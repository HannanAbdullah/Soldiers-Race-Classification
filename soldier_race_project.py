# -*- coding: utf-8 -*-
"""soldier_race_project_SDA1035-Hanan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16tZzV6YdJaQbdlAzro1-yfkNskGgiuOW

___

<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="CLRSWY"></p>

___

# WELCOME!

In this project, you must apply EDA processes for the development of predictive models. Handling outliers, domain knowledge and feature engineering will be challenges.

Also, this project aims to improve your ability to implement algorithms for Multi-Class Classification. Thus, you will have the opportunity to implement many algorithms commonly used for Multi-Class Classification problems.

Before diving into the project, please take a look at the determines and tasks.

# Determines

The 2012 US Army Anthropometric Survey (ANSUR II) was executed by the Natick Soldier Research, Development and Engineering Center (NSRDEC) from October 2010 to April 2012 and is comprised of personnel representing the total US Army force to include the US Army Active Duty, Reserves, and National Guard. In addition to the anthropometric and demographic data described below, the ANSUR II database also consists of 3D whole body, foot, and head scans of Soldier participants. These 3D data are not publicly available out of respect for the privacy of ANSUR II participants. The data from this survey are used for a wide range of equipment design, sizing, and tariffing applications within the military and has many potential commercial, industrial, and academic applications.

The ANSUR II working databases contain 93 anthropometric measurements which were directly measured, and 15 demographic/administrative variables explained below. The ANSUR II Male working database contains a total sample of 4,082 subjects. The ANSUR II Female working database contains a total sample of 1,986 subjects.


DATA DICT:
https://data.world/datamil/ansur-ii-data-dictionary/workspace/file?filename=ANSUR+II+Databases+Overview.pdf

---

To achieve high prediction success, you must understand the data well and develop different approaches that can affect the dependent variable.

Firstly, try to understand the dataset column by column using pandas module. Do research within the scope of domain (body scales, and race characteristics) knowledge on the internet to get to know the data set in the fastest way.

You will implement ***Logistic Regression, Support Vector Machine, XGBoost, Random Forest*** algorithms. Also, evaluate the success of your models with appropriate performance metrics.

At the end of the project, choose the most successful model and try to enhance the scores with ***SMOTE*** make it ready to deploy. Furthermore, use ***SHAP*** to explain how the best model you choose works.

# Tasks

#### 1. Exploratory Data Analysis (EDA)
- Import Libraries, Load Dataset, Exploring Data

    *i. Import Libraries*
    
    *ii. Ingest Data*
    
    *iii. Explore Data*
    
    *iv. Outlier Detection*
    
    *v.  Drop unnecessary features*

#### 2. Data Preprocessing
- Scale (if needed)
- Separete the data frame for evaluation purposes

#### 3. Multi-class Classification
- Import libraries
- Implement SVM Classifer
- Implement Decision Tree Classifier
- Implement Random Forest Classifer
- Implement XGBoost Classifer
- Compare The Models

# EDA
- Drop unnecessary colums
- Drop DODRace class if value count below 500 (we assume that our data model can't learn if it is below 500)

## 1. Import Libraries
Besides Numpy and Pandas, you need to import the necessary modules for data visualization, data preprocessing, Model building and tuning.

*Note: Check out the course materials.*
"""

!pip install scikit-plot
!pip install xgboost==0.90

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, make_scorer, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_auc_score
from scikitplot.metrics import plot_roc, precision_recall_curve, plot_precision_recall
from pandas.core.arrays.categorical import CategoricalAccessor
from sklearn.compose import make_column_transformer

#Classifires
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.utils import class_weight

import warnings
warnings.filterwarnings('ignore')
plt.rcParams["figure.figsize"] = (7,4)
pd.set_option('display.max_columns', 500)
pd.set_option('display.max_rows', 5000)
pd.options.display.float_format = '{:.3f}'.format

# !pip install -U imbalanced-learn

"""# 2. Ingest Data from links below and make a dataframe
- Soldiers Male : https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr
- Soldiers Female : https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq
"""

df_male = pd.read_csv("https://query.data.world/s/h3pbhckz5ck4rc7qmt2wlknlnn7esr", encoding="latin-1") # 'utf-8' can't decode
df_female = pd.read_csv(" https://query.data.world/s/sq27zz4hawg32yfxksqwijxmpwmynq", encoding="utf-8")

df_male.head()

df_female.head()

"""# 3. Explore and Visualize Data"""

df_male.shape, df_female.shape

df_male.info(verbose=True)

df_female.info(verbose=True)

df_male.describe()

df_female.describe()

df_male.duplicated().sum()

df_female.duplicated().sum()

df_male.isnull().sum()
#Ethnicity = 3180 nulls

df_female.isnull().sum()
#Ethnicity = 1467 nulls

df_male.columns

df_female.columns

df_male.columns.difference(df_female.columns)

df_male.rename(columns={'subjectid': 'SubjectId'}, inplace=True)

df_female.columns.equals(df_male.columns)

# Concatenate vertically (along rows)
df = pd.concat([df_male, df_female], axis=0, ignore_index=True)

df.shape

df.head()

Gender = df['Gender']
Gender.value_counts()

Gender.value_counts().plot.pie(autopct='%.2f')

df.info(verbose=True)

df.describe().T

df.corr()["DODRace"].sort_values(ascending=False)

df.DODRace.value_counts()

drop_DODRace= df.DODRace.value_counts()[df.DODRace.value_counts() < 500].index
drop_DODRace

# We list the DODRace with 500 or less observations.
# We will drop the observations of the DODRace in this list from our data.

for i in drop_DODRace:
    drop_index = df[df['DODRace'] == i].index
    df.drop(index = drop_index, inplace=True)

df.reset_index(drop=True, inplace=True)

df.shape

df.DODRace.value_counts()

drop_huge_nulls = []

for col in df:
    if(df[col].isnull().sum()>(df.shape[0]//3)):
        drop_huge_nulls.append(col)
drop_huge_nulls
#drop columns with null values greater than (5769/3 = 1923) => more than 30% of the data is null

df.drop(drop_huge_nulls, axis = 1, inplace = True)
df

df.SubjectNumericRace.value_counts()

df[["DODRace","SubjectNumericRace"]]

df.drop("SubjectNumericRace", axis = 1, inplace = True)
df
# SubjectNumericRace and DODRace columns have the same information about a subjectâ€™s self-reported race, so I drop it.

df[['Weightlbs','weightkg']]

df.drop("Weightlbs", axis = 1, inplace = True)
df
#Weightlbs and weightkg columns have the same information about weight, so I drop Weightlbs.

df_object = df.select_dtypes(include ="object").head()
df_object

# select_dtypes(include ="object") to filter only object type features

for col in df_object:
    print(f"{col:<25}: {df[col].nunique():<5}unique values")

for col in df_object:
    print(f"{col:<25}:", df[col].unique())

plt.figure(figsize=(10,10))
df.groupby(["Installation"])["DODRace"].value_counts().plot(kind="barh")

df.groupby(["Component"])["DODRace"].value_counts().plot(kind="barh")

df.groupby(["Branch"])["DODRace"].value_counts(normalize=True)

df.groupby(["Component","Branch"])["DODRace"].value_counts()

drop_cols = ["SubjectId","Date", "Installation", "Component", "Branch", "PrimaryMOS", "Heightin" ]
df.drop(columns=drop_cols, axis=1, inplace=True)

# Dropped because it isn't related to race (SubjectId, Date, Installation, Component, Branch, PrimaryMOS, Heightin)

df["Gender"] =df["Gender"].map({"Male":0,"Female":1})
df["Gender"]

df.WritingPreference.value_counts()

df["WritingPreference"] =df["WritingPreference"].map({"Right hand":0,"Left hand":1, "Either hand (No preference)":2})
df["WritingPreference"]

df.shape

df.isnull().sum().any()

df.head()

df.DODRace.value_counts().plot.pie(autopct='%.2f')

ax = sns.countplot(x='DODRace', data=df)
ax.bar_label(ax.containers[0])

ax = sns.countplot(x="DODRace", data = df, hue = "Gender")
for p in ax.containers:
    ax.bar_label(p)

# distribution by gender

sns.histplot(df.DODRace,kde = True)

plt.figure(figsize=(15,10))
sns.heatmap(df.corr(numeric_only=True),vmin = -1, vmax =1, cmap="coolwarm");

#Outliers in DODRace Column
plt.figure(figsize=(10,6))
sns.boxplot(df.DODRace)

fig = plt.figure(figsize=(50,30), dpi=200)

for i, col in enumerate(df.select_dtypes(["float", "int"]).columns):
        plt.subplot(20,5,i+1)
        ax = sns.boxplot(x=df[col])

plt.tight_layout();

index = 0
plt.figure(figsize=(50,30))
for feature in df.select_dtypes("number"):
    if feature != "DODRace":
        index += 1
        plt.subplot(20,5,index)
        sns.boxplot(x='DODRace',y=feature,data=df)

# check multicollinearity
df_temp = df.corr()

count = 0
feature =[]
collinear=[]
for col in df_temp.columns:
    for i in df_temp.index:
        if (df_temp[col][i]> .9 and df_temp[col][i] < 1) or (df_temp[col][i]< -.9 and df_temp[col][i] > -1) :
                feature.append(col)
                collinear.append(i)
                # print(f"multicolinearity alert in between {col} - {i}")
print("Number of strong corelated features:", count)

df_col = pd.DataFrame([feature, collinear], index=["feature","collinear"]).T
df_col

df_col.value_counts("feature")

df["DODRace"] = df.DODRace.map({1 : "White", 2 : "Black", 3 : "Hispanic"})
df.DODRace.value_counts()

"""# 4. DATA Preprocessing
- In this step we divide our data to X(Features) and y(Target) then ,
- To train and evaluation purposes we create train and test sets,
- Lastly, scale our data if features not in same scale. Why?
"""

X = df.drop(columns ='DODRace', axis =1)
# X = pd.get_dummies(data=X, drop_first=True)
y = df.DODRace

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=101)
# use stratify=y whether your data is inbalanced or balanced.
#I put 80% for training and 20% for testing, since the dataset is small and imbalanced

print("Train features shape : ", X_train.shape)
print("Train target shape   : ", y_train.shape)
print("Test features shape  : ", X_test.shape)
print("Test target shape    : ", y_test.shape)

print(y.value_counts(normalize=True))
print()
print(y_train.value_counts(normalize=True))
print()
print(y_test.value_counts(normalize=True))

# Distributed targets 80% to the train set and 20% to the test set.

"""# 5. Modelling
- Fit the model with train dataset
- Get predict from vanilla model on both train and test sets to examine if there is over/underfitting   
- Apply GridseachCV for both hyperparemeter tuning and sanity test of our model.
- Use hyperparameters that you find from gridsearch and make final prediction and evaluate the result according to chosen metric.

## eval_metric Function
"""

def eval_metric(model, X_train, y_train, X_test, y_test):
    y_train_pred = model.predict(X_train)
    y_pred = model.predict(X_test)

    print("Test_Set---------------------------------------------")
    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    print()
    print("Train_Set--------------------------------------------")
    print(confusion_matrix(y_train, y_train_pred))
    print(classification_report(y_train, y_train_pred))

"""## 5.1. Logistic model

### Vanilla Logistic Model
"""

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

operations = [("OneHotEncoder", column_transform),("logistic",LogisticRegression(class_weight="balanced", random_state=101))]
logistic_pipe_model = Pipeline(steps = operations)
logistic_pipe_model.fit(X_train,y_train)

y_pred = logistic_pipe_model.predict(X_test)
y_pred

y_pred_proba = logistic_pipe_model.predict_proba(X_test)
y_pred_proba

ConfusionMatrixDisplay.from_estimator(logistic_pipe_model,X_test,y_test)

eval_metric(logistic_pipe_model, X_train, y_train, X_test, y_test)
#no overfitting
#Since the dataset is imbalance, so we need to focus more on Hispanics class to improve accuracy

"""### Cross Validate"""

f1score = make_scorer(f1_score, average="weighted")

operations = [("OneHotEncoder", column_transform),("logistic",LogisticRegression(class_weight="balanced", random_state=101))]

logistic_pipe_model_CV = Pipeline(steps=operations)

scores = cross_validate(logistic_pipe_model_CV, X_train, y_train, scoring = f1score, cv = 10, return_train_score=True)
df_scores = pd.DataFrame(scores, index = range(1, 11))

pd.DataFrame(df_scores)

pd.DataFrame(df_scores.mean()[2:])
#no overfitting

"""### Cross Validate for Hispanic       """

f1_Hispanic = make_scorer(f1_score, average = None, labels =["Hispanic"])
precision_Hispanic = make_scorer(precision_score, average = None, labels =["Hispanic"])
recall_Hispanic = make_scorer(recall_score, average = None, labels =["Hispanic"])


Hispanic_scoring = {"f1_Hispanic":f1_Hispanic,
           "precision_Hispanic":precision_Hispanic,
           "recall_Hispanic":recall_Hispanic}

operations = [("OneHotEncoder", column_transform),("logistic",LogisticRegression(class_weight="balanced", random_state=101))]
logistic_pipe_model_CV_Hispanic = Pipeline(steps=operations)

scores = cross_validate(logistic_pipe_model_CV_Hispanic, X_train, y_train, scoring = Hispanic_scoring, cv = 10, return_train_score=True)
df_scores = pd.DataFrame(scores, index = range(1, 11))

pd.DataFrame(df_scores.mean()[2:])
#There is overfitting in Hispanic class

"""### Logistic Model GridsearchCV"""

operations = [("OneHotEncoder", column_transform),("logistic",LogisticRegression(random_state=101, max_iter=50000))]

logistic_pipe_model = Pipeline(steps=operations)

logistic_pipe_model.get_params()

param_grid = { "logistic__class_weight" : ["balanced", None],
               'logistic__penalty': ["l1","l2"],
               'logistic__solver' : ['saga','lbfgs','liblinear'],
               'logistic__C' :[0.001,0.01, 0.1, 0.5, 1, 5]
             }

f1_Hispanic =  make_scorer(f1_score, average=None, labels=["Hispanic"] )
# Hispanic class is the worst scoring for our model and we need to foucs on it

logistic_pipe_model_grid_CV = GridSearchCV(logistic_pipe_model, param_grid = param_grid, cv=5, scoring = f1_Hispanic, return_train_score=True)

logistic_pipe_model_grid_CV.fit(X_train,y_train)

logistic_pipe_model_grid_CV.best_params_

logistic_pipe_model_grid_CV.best_estimator_

pd.DataFrame(logistic_pipe_model_grid_CV.cv_results_).loc[logistic_pipe_model_grid_CV.best_index_, ["mean_test_score", "mean_train_score"]]

y_pred = logistic_pipe_model_grid_CV.predict(X_test)
y_pred

ConfusionMatrixDisplay.from_estimator(logistic_pipe_model_grid_CV, X_test, y_test);

eval_metric(logistic_pipe_model_grid_CV, X_train, y_train, X_test, y_test)

"""### Class prediction"""

test_data = pd.concat([X_test, y_test], axis=1)
test_data["Pred"] = y_pred
test_data["Pred_proba_Black"] = y_pred_proba[:,0]
test_data["Pred_proba_Hispanic"] = y_pred_proba[:,1]
test_data["Pred_proba_White"] = y_pred_proba[:,2]
test_data.sample(10)

"""### ROC (Receiver Operating Curve) and AUC (Area Under Curve)"""

operations = [("OneHotEncoder", column_transform), ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

logistic_best_pipe_model = Pipeline(steps=operations)

logistic_best_pipe_model.fit(X_train, y_train)

y_pred_proba = logistic_best_pipe_model.predict_proba(X_test)

plot_roc(y_test, y_pred_proba)
plt.show();

y_test_dummies = pd.get_dummies(y_test).values

roc_auc_score(y_test_dummies[:, 0], y_pred_proba[:, 0])
# roc_auc score for Black

roc_auc_score(y_test_dummies[:, 1], y_pred_proba[:, 1])
# roc_auc score for Hispanic

roc_auc_score(y_test_dummies[:, 2], y_pred_proba[:, 2])
# roc_auc score for White

y_test[:5]

y_test_dummies[:5]

"""### Precision Recall Curve"""

operations = [("OneHotEncoder", column_transform), ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

logistic_best_pipe_model = Pipeline(steps=operations)

logistic_best_pipe_model.fit(X_train, y_train)

y_pred_proba = logistic_best_pipe_model.predict_proba(X_test)

plot_precision_recall(y_test, y_pred_proba)
plt.show();

from sklearn.metrics import average_precision_score, roc_auc_score

y_test_dummies = pd.get_dummies(y_test).values

average_precision_score(y_test_dummies[:, 0], y_pred_proba[:, 0])
# PR score for Black

average_precision_score(y_test_dummies[:, 1], y_pred_proba[:, 1])
# PR score for Hispanic

average_precision_score(y_test_dummies[:, 2], y_pred_proba[:, 2])
# PR score for White

"""### Best Logistic Regression Results"""

operations = [("OneHotEncoder", column_transform), ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

logistic_best_pipe_model = Pipeline(steps=operations)

logistic_best_pipe_model.fit(X_train, y_train)

y_test_dummies = pd.get_dummies(y_test).values

y_pred_proba = logistic_best_pipe_model.predict_proba(X_test)

y_pred = logistic_best_pipe_model.predict(X_test)

log_AP = average_precision_score(y_test_dummies[:, 1], y_pred_proba[:,1])
log_auc = roc_auc_score(y_test_dummies[:, 1], y_pred_proba[:,1])
log_f1 = f1_score(y_test, y_pred, average=None, labels=["Hispanic"])
log_recall = recall_score(y_test, y_pred, average=None, labels=["Hispanic"])

print("Best Logistic model results:")
print(f"AP: {log_AP}, AUC: {log_auc}, F1_score: {log_f1[0]}, Recall: {log_recall[0]}")

"""## 5.2. SVC

### Vanilla SVC model
"""

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

operations = [("OneHotEncoder", column_transform),("SVC", SVC(probability=True , class_weight="balanced", random_state=101))]
SVM_pipe_model = Pipeline(steps=operations)

SVM_pipe_model.fit(X_train, y_train)
eval_metric(SVM_pipe_model, X_train, y_train, X_test, y_test)

y_pred_proba = SVM_pipe_model.predict_proba(X_test)

plot_precision_recall(y_test, y_pred_proba)
plt.show();

"""### Cross Validate"""

f1_Hispanic = make_scorer(f1_score, average = None, labels =["Hispanic"])
precision_Hispanic = make_scorer(precision_score, average = None, labels =["Hispanic"])
recall_Hispanic = make_scorer(recall_score, average = None, labels =["Hispanic"])

Hispanic_scoring = {"f1_Hispanic":f1_Hispanic,
           "precision_Hispanic":precision_Hispanic,
           "recall_Hispanic":recall_Hispanic}

operations = [("OneHotEncoder", column_transform),("SVC", SVC(probability=True , class_weight="balanced", random_state=101))]
SVM_pipe_model_CV = Pipeline(steps=operations)

scores = cross_validate(SVM_pipe_model_CV,
                        X_train,
                        y_train,
                        scoring=Hispanic_scoring,
                        cv = 10,
                        return_train_score=True)
df_scores = pd.DataFrame(scores, index = range(1, 11))

pd.DataFrame(df_scores[2:])

pd.DataFrame(df_scores.mean()[2:])
#Overfitting in Hispanic class

"""###  SVC Model GridsearchCV"""

param_grid = {'SVC__C': [0.001, 0.05, 0.01, 0.1],
              'SVC__gamma': ["scale", "auto", 0.01, 0.1,0.5],
              'SVC__kernel': ['rbf', 'linear'],
              'SVC__decision_function_shape' : ['ovr','ovo'],
              'SVC__class_weight': ["balanced", None]}

operations = [("OneHotEncoder", column_transform),("SVC", SVC(probability=True , random_state=101))]
SVM_pipe_model = Pipeline(steps=operations)

SVM_pipe_model_grid_CV = GridSearchCV(SVM_pipe_model,
                              param_grid,
                              scoring=f1_Hispanic,
                              cv=5,
                              return_train_score=True)

SVM_pipe_model_grid_CV.fit(X_train, y_train)

SVM_pipe_model_grid_CV.best_estimator_

SVM_pipe_model_grid_CV.best_params_

pd.DataFrame(SVM_pipe_model_grid_CV.cv_results_).loc[SVM_pipe_model_grid_CV.best_index_, ["mean_test_score", "mean_train_score"]]

eval_metric(SVM_pipe_model_grid_CV, X_train, y_train, X_test, y_test)

"""### CLass Prediction"""

test_data = pd.concat([X_test, y_test], axis=1)
test_data["Pred"] = y_pred
test_data["Pred_proba_Black"] = y_pred_proba[:,0]
test_data["Pred_proba_Hispanic"] = y_pred_proba[:,1]
test_data["Pred_proba_White"] = y_pred_proba[:,2]
test_data.sample(10)

"""### ROC (Receiver Operating Curve) and AUC (Area Under Curve)"""

operations = [("OneHotEncoder", column_transform),("SVC", SVC(C= 0.1, gamma= "scale", kernel= 'linear', probability=True, class_weight=None, decision_function_shape = 'ovr',random_state=101))]

SVM_Best_pipe_model = Pipeline(steps=operations)

SVM_Best_pipe_model.fit(X_train, y_train)

y_pred_proba = SVM_Best_pipe_model.predict_proba(X_test)

plot_roc(y_test, y_pred_proba)
plt.show();

"""### Precision Recall Curve"""

operations = [("OneHotEncoder", column_transform),("SVC", SVC(C= 0.1, gamma= "scale", kernel= 'linear', probability=True, class_weight=None, decision_function_shape = 'ovr',random_state=101))]
SVM_Best_pipe_model = Pipeline(steps=operations)

SVM_Best_pipe_model.fit(X_train, y_train)

y_pred_proba = SVM_Best_pipe_model.predict_proba(X_test)

plot_precision_recall(y_test, y_pred_proba)
plt.show();

"""### Best SVC Results"""

operations = [("OneHotEncoder", column_transform),("SVC", SVC(C= 0.1, gamma= "scale", kernel= 'linear', probability=True, class_weight=None, decision_function_shape = 'ovr',random_state=101))]
SVM_Best_pipe_model = Pipeline(steps=operations)

SVM_Best_pipe_model.fit(X_train, y_train)

y_pred_proba = SVM_Best_pipe_model.predict_proba(X_test)

y_test_dummies = pd.get_dummies(y_test).values

y_pred = SVM_Best_pipe_model.predict(X_test)

svc_AP = average_precision_score(y_test_dummies[:,1], y_pred_proba[:,1])
svc_auc = roc_auc_score(y_test_dummies[:,1], y_pred_proba[:,1])
svc_f1 = f1_score(y_test, y_pred, average=None, labels=["Hispanic"])
svc_recall = recall_score(y_test, y_pred, average=None, labels=["Hispanic"])

print("Best SVM model results:")
print(f"AP: {svc_AP}, AUC: {svc_auc}, F1_score: {svc_f1[0]}, Recall: {svc_recall[0]}")

"""## 5.3. RF

### Vanilla RF Model
"""

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

ord_enccoding = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)

column_transformer = make_column_transformer((ord_enccoding, categoricals_cols), remainder='passthrough')

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier(class_weight="balanced",random_state=101))]
RF_pipe_model = Pipeline(steps=operations)

RF_pipe_model.fit(X_train, y_train)

ConfusionMatrixDisplay.from_estimator(RF_pipe_model,X_test,y_test)

eval_metric(RF_pipe_model, X_train, y_train, X_test, y_test)
# Overfitting

"""### Cross Validation"""

f1_Hispanic = make_scorer(f1_score, average = None, labels =["Hispanic"])
precision_Hispanic = make_scorer(precision_score, average = None, labels =["Hispanic"])
recall_Hispanic = make_scorer(recall_score, average = None, labels =["Hispanic"])

Hispanic_scoring = {"f1_Hispanic":f1_Hispanic,
           "precision_Hispanic":precision_Hispanic,
           "recall_Hispanic":recall_Hispanic}

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier(class_weight="balanced",random_state=101))]
RF_pipe_model_CV = Pipeline(steps=operations)

scores = cross_validate(RF_pipe_model_CV,
                        X_train,
                        y_train,
                        scoring=Hispanic_scoring,
                        cv = 10,
                        return_train_score=True)
df_scores = pd.DataFrame(scores, index = range(1, 11))

pd.DataFrame(df_scores[2:])

pd.DataFrame(df_scores.mean()[2:])

"""### RF Model GridsearchCV"""

param_grid = {'RF__n_estimators':[400,500],
             'RF__criterion': ["gini","entropy"],
             'RF__max_depth':[2, 3, 5, 6],
             'RF__min_samples_split':[18,20,22],
             'RF__class_weight': ['balanced',None],
             'RF__max_features': ['auto', None, 30, 50]
              }

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier( random_state=101))]
RF_pipe_model = Pipeline(steps=operations)

RF_pipe_model_grid_CV = GridSearchCV(RF_pipe_model,
                              param_grid,
                              scoring=f1_Hispanic,
                              n_jobs=-1,
                              cv =5,
                              verbose=3,
                              return_train_score=True)

RF_pipe_model_grid_CV.fit(X_train,y_train)

RF_pipe_model_grid_CV.best_estimator_

pd.DataFrame(RF_pipe_model_grid_CV.cv_results_).loc[RF_pipe_model_grid_CV.best_index_, ["mean_test_score", "mean_train_score"]]

ConfusionMatrixDisplay.from_estimator(RF_pipe_model_grid_CV,X_test,y_test)

eval_metric(RF_pipe_model_grid_CV, X_train, y_train, X_test, y_test)

"""### ROC Curve and AUC"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier( class_weight='balanced',  max_depth=6, max_features=50, min_samples_split=20, n_estimators=500,random_state=101))]

RF_best_pipe_model = Pipeline(steps=operations)

RF_best_pipe_model.fit(X_train,y_train)

y_pred_proba = RF_best_pipe_model.predict_proba(X_test)

plot_roc(y_test, y_pred_proba)
plt.show();

"""### PR Curve"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier( class_weight='balanced',  max_depth=6, max_features=50, min_samples_split=20, n_estimators=500,random_state=101))]

RF_best_pipe_model = Pipeline(steps=operations)

RF_best_pipe_model.fit(X_train,y_train)

y_pred_proba = RF_best_pipe_model.predict_proba(X_test)

plot_precision_recall(y_test, y_pred_proba)
plt.show();

"""### Best Random Forest Results"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("RF", RandomForestClassifier( class_weight='balanced',  max_depth=6, max_features=50, min_samples_split=20, n_estimators=500,random_state=101))]

RF_best_pipe_model = Pipeline(steps=operations)

RF_best_pipe_model.fit(X_train,y_train)

y_pred_proba = RF_best_pipe_model.predict_proba(X_test)

y_pred = RF_best_pipe_model.predict(X_test)

y_test_dummies = pd.get_dummies(y_test).values

rf_AP = average_precision_score(y_test_dummies[:,1], y_pred_proba[:,1])
rf_auc = roc_auc_score(y_test_dummies[:,1], y_pred_proba[:,1])
rf_f1 = f1_score(y_test, y_pred, average=None, labels=["Hispanic"])
rf_recall = recall_score(y_test, y_pred, average=None, labels=["Hispanic"])

print("Best Random Forest model results:")
print(f"AP: {rf_AP}, AUC: {rf_auc}, F1_score: {rf_f1[0]}, Recall: {rf_recall[0]}")

"""## 5.4. XGBoost

### Vanilla XGBoost Model
"""

y_train_xgboot = y_train.map({"Black": 0, "Hispanic": 1, "White": 2})
y_test_xgboot = y_test.map({"Black": 0, "Hispanic": 1, "White": 2})
# need to map the labels since it works only on the numerical data.

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier( random_state=101))]
XGBoost_pipe_model = Pipeline(steps=operations)

classes_weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train3)
classes_weights
# It has no class_weight hyperparameter for multiclass, so use the sample_weight hyperparameter within the fit function.

data = {"weights": classes_weights, "label": y_train_xgboot}
dataf = pd.DataFrame(data)

dataf.head()

dataf.groupby("label").value_counts()

XGBoost_pipe_model.fit(X_train, y_train_xgboot, XGBoost__sample_weight=classes_weights)

ConfusionMatrixDisplay.from_estimator(XGBoost_pipe_model,X_test,y_test_xgboot)

eval_metric(XGBoost_pipe_model, X_train, y_train_xgboot, X_test, y_test_xgboot)

"""### Cross Validation"""

f1_Hispanic_xgb = make_scorer(f1_score, average = None, labels =[1])
precision_Hispanic_xgb = make_scorer(precision_score, average = None, labels =[1])
recall_Hispanic_xgb = make_scorer(recall_score, average = None, labels =[1])

Hispanic_scoring_xgb = {"f1_Hispanic":f1_Hispanic_xgb,
           "precision_Hispanic":precision_Hispanic_xgb,
           "recall_Hispanic":recall_Hispanic_xgb}

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier( random_state=101))]
XGBoost_pipe_model_CV = Pipeline(steps=operations)

scores = cross_validate(XGBoost_pipe_model_CV,
                        X_train,
                        y_train_xgboot,
                        scoring=Hispanic_scoring_xgb,
                        cv = 10,
                        return_train_score=True,
                        fit_params={"XGBoost__sample_weight":classes_weights})

df_scores = pd.DataFrame(scores, index = range(1,11))
pd.DataFrame(df_scores.mean()[2:])
#Overfitting in Hispanic class

"""### XGBoost Model GridsearchCV"""

param_grid = {"XGBoost__n_estimators":[50 , 100, 200, 300],
              'XGBoost__max_depth':[3,4,5,6],
              "XGBoost__learning_rate": [0.01, 0.1, 0.2, 0.3],
              "XGBoost__subsample":[0.5, 0.8, 1],
              "XGBoost__colsample_bytree":[0.5,0.8, 1]}

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier(random_state=101))]
XGBoost_pipe_model = Pipeline(steps=operations)

XGBoost_pipe_model_grid_CV = GridSearchCV(XGBoost_pipe_model,
                              param_grid,
                              scoring=f1_Hispanic_xgb,
                              cv=5,
                              n_jobs=-1,
                              return_train_score=True,
                                          )

XGBoost_pipe_model_grid_CV.fit(X_train, y_train_xgboot, XGBoost__sample_weight=classes_weights)

XGBoost_pipe_model_grid_CV.best_estimator_

XGBoost_pipe_model_grid_CV.best_params_

pd.DataFrame(XGBoost_pipe_model_grid_CV.cv_results_).loc[ XGBoost_pipe_model_grid_CV.best_index_, ["mean_test_score", "mean_train_score"]]

XGBoost_pipe_model_grid_CV.best_score_

ConfusionMatrixDisplay.from_estimator(XGBoost_pipe_model_grid_CV,X_test,y_test_xgboot)

eval_metric(XGBoost_pipe_model_grid_CV, X_train, y_train_xgboot, X_test, y_test_xgboot)

"""### ROC Curve and AUC"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier(colsample_bytree = 0.5,
                                                learning_rate = 0.1, max_depth = 4, n_estimators = 200, subsample = 1, random_state=101 ))]


XGBoost_best_pipe_model = Pipeline(steps = operations)

XGBoost_best_pipe_model.fit(X_train, y_train_xgboot, XGBoost__sample_weight=classes_weights)

y_pred_proba = XGBoost_best_pipe_model.predict_proba(X_test)

plot_roc(y_test_xgboot, y_pred_proba)
plt.show();

"""### PR Curve"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier(colsample_bytree = 0.5,
                                                learning_rate = 0.1, max_depth = 4, n_estimators = 200, subsample = 1, random_state=101 ))]


XGBoost_best_pipe_model = Pipeline(steps = operations)

XGBoost_best_pipe_model.fit(X_train, y_train_xgboot, XGBoost__sample_weight=classes_weights)

y_pred_proba = XGBoost_best_pipe_model.predict_proba(X_test)

plot_precision_recall(y_test_xgboot, y_pred_proba)
plt.show();

"""### Best XGBoost Results"""

operations = [("OrdinalEncoder", column_transformer),("scaler", StandardScaler()), ("XGBoost", XGBClassifier(colsample_bytree = 0.5,
                                                learning_rate = 0.1, max_depth = 4, n_estimators = 200, subsample = 1, random_state=101 ))]


XGBoost_best_pipe_model = Pipeline(steps = operations)

XGBoost_best_pipe_model.fit(X_train, y_train_xgboot, XGBoost__sample_weight=classes_weights)

y_pred_proba = XGBoost_best_pipe_model.predict_proba(X_test)

y_pred = XGBoost_best_pipe_model.predict(X_test)

y_test_dummies = pd.get_dummies(y_test_xgboot).values

xgb_AP = average_precision_score(y_test_dummies[:,1], y_pred_proba[:,1])
xgb_auc = roc_auc_score(y_test_dummies[:,1], y_pred_proba[:,1])
xgb_f1 = f1_score(y_test_xgboot, y_pred, average=None, labels=[1])
xgb_recall = recall_score(y_test_xgboot, y_pred, average=None, labels=[1])

print("Best XGBoost model results:")
print(f"AP: {xgb_AP}, AUC: {xgb_auc}, F1_score: {xgb_f1[0]}, Recall: {xgb_recall[0]}")

"""# 6. Comparing Models"""

compare = pd.DataFrame({"Model": ["logistic", "SVC",  "RF", "XGBoost"],
                        "F1": [log_f1[0], svc_f1[0], rf_f1[0], xgb_f1[0]],
                        "Recall": [log_recall[0], svc_recall[0], rf_recall[0], xgb_recall[0]],
                        "AP": [log_AP, svc_AP, rf_AP, xgb_AP],
                       "ROC_AUC":[log_auc, svc_auc, rf_auc,xgb_auc]})    # Dengesiz datasetlerinde modelin genel performansi.

def labels(ax):   # Sayilari yazdirmak icin.
    for p in ax.patches:
        width = p.get_width()                        # get bar length
        ax.text(width,                               # set the text at 1 unit right of the bar
                p.get_y() + p.get_height() / 2,      # get Y coordinate + X coordinate / 2
                '{:1.3f}'.format(width),             # set variable to display, 2 decimals
                ha = 'left',                         # horizontal alignment
                va = 'center')                       # vertical alignment

plt.figure(figsize=(15,15))
plt.subplot(411)
compare = compare.sort_values(by="F1", ascending=False)
ax=sns.barplot(x="F1", y="Model", data=compare, palette="Blues_d")        # f1 score
labels(ax)

plt.subplot(412)
compare = compare.sort_values(by="Recall", ascending=False)
ax=sns.barplot(x="Recall", y="Model", data=compare, palette="Blues_d")   # recall score
labels(ax)

plt.subplot(413)
compare = compare.sort_values(by="AP", ascending=False)
ax=sns.barplot(x="AP", y="Model", data=compare, palette="Blues_d")       # average precision score
labels(ax)

plt.subplot(414)
compare = compare.sort_values(by="ROC_AUC", ascending=False)
ax=sns.barplot(x="ROC_AUC", y="Model", data=compare, palette="Blues_d")       # average auc score
labels(ax)
plt.show()

"""---
---

---
---

# 7. Before the Deployment
- Choose the model that works best based on your chosen metric
- For final step, fit the best model with whole dataset to get better performance.
- And your model ready to deploy, dump your model and scaler.
"""

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

#The best model in logistic regression model
best_operations = [("OneHotEncoder", column_transform), ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

Best_model = Pipeline(steps = best_operations)

Best_model.fit(X_train, y_train)

X.describe()

human_avg = X.describe().loc["mean"]
human_avg

male_avg = X[X.Gender == 0].describe(include="all").loc["mean"]
male_avg

male_avg["Gender"] = 0 # "Male"
male_avg["SubjectsBirthLocation"] = "New York"
male_avg["WritingPreference"] = 0 #"Right hand"

pd.DataFrame(male_avg).T

Best_model.predict(pd.DataFrame(male_avg).T)

# we can say that the average values of male soldiers are very
# close to White soldiers.

female_avg = X[X.Gender == 1].describe(include="all").loc["mean"]
female_avg

female_avg["Gender"] = 1 # "Female"
female_avg["SubjectsBirthLocation"] = "New York"
female_avg["WritingPreference"] = 0 #"Right hand"

pd.DataFrame(female_avg).T

Best_model.predict(pd.DataFrame(female_avg).T)

# we can say that the average values of male soldiers are very
# close to White soldiers.

pd.DataFrame([df.loc[150]])

Best_model.predict(X.loc[[150]])

y[150]

"""## Other Evaluation Metrics for Multiclass Classification

- Evaluation metrics
https://towardsdatascience.com/comprehensive-guide-on-multiclass-classification-metrics-af94cfb83fbd
"""

from sklearn.metrics import matthews_corrcoef

y_pred = Best_model.predict(X_test)

matthews_corrcoef(y_test, y_pred)

from sklearn.metrics import cohen_kappa_score

cohen_kappa_score(y_test, y_pred)

"""# 8. SMOTE
https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/

##  Smote implement
"""

!pip install imblearn

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as imbpipeline

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

X_train_1HotEncoding = column_transform.fit_transform (X_train)

overSample_1 = SMOTE()
overSample_2 = SMOTE(sampling_strategy={"Hispanic": 1050})

underSample_1 = RandomUnderSampler()
underSample_2 = RandomUnderSampler(sampling_strategy={"White": 2000})

X_train_overSampled_1, y_train_overSampled_1 = overSample_1.fit_resample(X_train_1HotEncoding, y_train)
X_train_overSampled_1.shape

y_train_overSampled_1.value_counts()

X_train_overSampled_2, y_train_overSampled_2 = overSample_2.fit_resample(X_train_1HotEncoding, y_train)
X_train_overSampled_2.shape

y_train_overSampled_2.value_counts()

X_train_underSampled_1, y_train_underSampled_1 = underSample_1.fit_resample(X_train_1HotEncoding, y_train)
X_train_underSampled_1.shape

y_train_underSampled_1.value_counts()

X_train_underSampled_2, y_train_underSampled_2 = underSample_2.fit_resample(X_train_1HotEncoding, y_train)
X_train_underSampled_2.shape

y_train_underSampled_2.value_counts()

over_and_under_sample = [("overSampled", overSample_2), ("underSampled", underSample_2)]

resampled_pipeline = imbpipeline(steps = over_and_under_sample)

X_resampled, y_resampled = resampled_pipeline.fit_resample(X_train_1HotEncoding, y_train)
X_resampled.shape

y_resampled.value_counts()

"""## Logistic Regression Over/ Under Sampling"""

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

best_log_operations = [
    ("OneHotEncoder", column_transform),
    ("overSampled", overSample_2),
    ("underSampled", underSample_2),
     ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

Best_smote_model_pipeline = imbpipeline(steps = best_log_operations)

Best_smote_model_pipeline.fit(X_train, y_train)

eval_metric(Best_smote_model_pipeline, X_train, y_train, X_test, y_test)

f1_Hispanic = make_scorer(f1_score, average = None, labels =["Hispanic"])
precision_Hispanic = make_scorer(precision_score, average = None, labels =["Hispanic"])
recall_Hispanic = make_scorer(recall_score, average = None, labels =["Hispanic"])

Hispanic_scoring = {"f1_Hispanic":f1_Hispanic,
           "precision_Hispanic":precision_Hispanic,
           "recall_Hispanic":recall_Hispanic}

#cross validation
Best_smote_model_CV = cross_validate(Best_smote_model_pipeline, X_train, y_train, scoring = Hispanic_scoring, cv = 10, n_jobs=-1, return_train_score=True)

df_scores = pd.DataFrame(Best_smote_model_CV, index = range(1, 11))
df_scores.mean()[2:]

"""# 9. SHAP"""

!pip install shap

categoricals_cols = X_train.select_dtypes("object").columns
categoricals_cols

column_transform = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

X_train_transform = column_transform.fit_transform (X_train)
X_test_transform = column_transform.transform (X_test)

best_model_shape_saga = LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='saga', max_iter=50000, random_state=101)

best_model_shape_saga.fit(X_train_transform, y_train)

eval_metric(best_model_shape_saga, X_train_transform, y_train, X_test_transform, y_test)

best_model_shape_liblinear = LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101)

best_model_shape_liblinear.fit(X_train_transform, y_train)

eval_metric(best_model_shape_liblinear, X_train_transform, y_train, X_test_transform, y_test)

best_model_operations = [
    ("OneHotEncoder", column_transform),
    ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

Best_model_pipeline = Pipeline(steps = best_model_operations)

f1_Hispanic = make_scorer(f1_score, average = None, labels =["Hispanic"])
precision_Hispanic = make_scorer(precision_score, average = None, labels =["Hispanic"])
recall_Hispanic = make_scorer(recall_score, average = None, labels =["Hispanic"])

Hispanic_scoring = {"f1_Hispanic":f1_Hispanic,
           "precision_Hispanic":precision_Hispanic,
           "recall_Hispanic":recall_Hispanic}

Best_model_CV_scores = cross_validate (Best_model_pipeline, X_train , y_train, scoring = Hispanic_scoring, cv = 10, n_jobs=-1, return_train_score=True)

Best_model_scores = pd.DataFrame (Best_model_CV_scores, index = range(1,11))
Best_model_scores.mean()[2:]

features_shape = column_transform.get_feature_names_out()
pd.DataFrame(features_shape)

features_shape

"""### SHAP values for test data"""

import shap

exp = shap.LinearExplainer (best_model_shape_liblinear, X_train_transform)

shap_values = exp.shap_values(X_test_transform)

shap.summary_plot(shap_values, max_display = 500, feature_names = features_shape, plot_size = (15,100) )

selected_features = [ 'span', 'stature','shouldercircumference', 'waistcircumference',
                       'radialestylionlength','bideltoidbreadth', 'waistdepth',
                      'forearmhandlength', 'footbreadthhorizontal','axillaheight',
                       'buttockkneelength', 'forearmcircumferenceflexed',
                      'sleevelengthspinewrist', 'buttockheight', 'weightkg',
                      'bizygomaticbreadth', 'shoulderlength',  'balloffootcircumference',
                      'earlength',   'forearmcenterofgriplength', 'buttockcircumference',
                      'poplitealheight', 'biacromialbreadth',  'handlength', 'hipbreadth',
                      'Age', 'bimalleolarbreadth', 'headlength', "SubjectsBirthLocation"]

X_important_features = X[selected_features]
X_important_features.head()

categoricals_cols2 = X_important_features.select_dtypes("object").columns
categoricals_cols2

X_important_features.shape

X_train2, X_test2, y_train2, y_test2 = train_test_split( X_important_features, y, test_size=0.2, stratify=y, random_state=101)

column_transform_shap = make_column_transformer(
    (OneHotEncoder(handle_unknown="ignore", sparse_output=False), categoricals_cols2),
    remainder=StandardScaler(),
    verbose_feature_names_out=False,
)

best_model_operations = [
    ("OneHotEncoder", column_transform_shap),
    ("logistic", LogisticRegression(class_weight='balanced', C=1, penalty = 'l1', solver='liblinear', max_iter=50000, random_state=101))]

Best_model_pipeline_shap = Pipeline(steps = best_model_operations)

Best_model_pipeline_shap.fit(X_train2, y_train2)

eval_metric(Best_model_pipeline_shap, X_train2, y_train2, X_test2, y_test2)

#ROC and AUC curve
y_pred_proba = Best_model_pipeline_shap.predict_proba(X_test2)

plot_roc(y_test2, y_pred_proba)
plt.show();

#PR curve
plot_precision_recall(y_test2, y_pred_proba)
plt.show();

Best_model_pipeline_shap_CV = Pipeline(steps = best_model_operations)

Best_model_CV_scores = cross_validate (Best_model_pipeline_shap_CV, X_train2 , y_train2, scoring = Hispanic_scoring, cv = 10, n_jobs=-1, return_train_score=True)

Best_model_scores = pd.DataFrame (Best_model_CV_scores, index = range(1,11))
Best_model_scores.mean()[2:]

"""**Without Feature Selection**

*   test_f1_Hispanic           0.649
*   train_f1_Hispanic          0.710
*   test_precision_Hispanic    0.656
*   train_precision_Hispanic   0.708
*   test_recall_Hispanic       0.646
*   train_recall_Hispanic      0.712

I noticed that the results without feature selection process is better.

# ___
<p style="text-align: center;"><img src="https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV" class="img-fluid" alt="CLRSWY"></p>

___
"""